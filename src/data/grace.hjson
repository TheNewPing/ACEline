{
    general: {
        lammps_bin_path: "/home/erodaro/lammps_grace/lammps/build/lmp",
        model_name: grace
        best_n_models: 5
        hpc: true
        cluster: 'snellius'
        sweep_path: "/home/erodaro/POTline/test_refactor/grace"
    }
    deep_training: {
        max_epochs: 1,
    }
    inference: {
        prerun_steps: 100,
        max_steps: 1100,
    }
    data_analysis: {
        lammps_inps_path: "/home/erodaro/POTline/src/potline/properties_simulator/pot_testing/lmps_inputs",
        pps_python_path: "/home/erodaro/POTline/src/potline/properties_simulator/pot_testing/py_pps",
        ref_data_path: "/home/erodaro/POTline/src/potline/properties_simulator/pot_testing/REF_DATA",
        email: "e.rodaro@rug.nl"
    }
    hyper_search: {
        max_iter: 1,
        n_initial_points: 5
        n_points: 10
        strategy: "cl_min"
        energy_weight: 0.3
        optimizer_params: {
            "cutoff": 6.0,
            "seed": 42
            "metadata": {
                "purpose": "Potential fit"
                },
            "data": {
                "filename": "/home/erodaro/POTline/src/data/Ogata_DB.pckl.gzip",
                "test_size": 0.10
            },
            "potential": {
                "elements": ["Fe"],
                preset: GRACE_1LAYER
                kwargs: {lmax: 4, n_rad_max: 32, max_order: 4, n_mlp_dens: 12}
                scale: True
            },
            "fit": {
                loss: {
                    energy: { 
                        weight: 1, 
                        type: huber
                        delta: 0.01 
                    },
                    forces: {
                        weight: 5,
                        type: huber
                        delta: 0.01 
                    },
                }
                maxiter: 1 # Number of epochs / iterations

                optimizer: Adam
                opt_params: {
                            learning_rate: 0.01,
                            amsgrad: True,
                            use_ema: True,
                            ema_momentum: 0.99,
                            weight_decay: null,
                            clipvalue: 1.0,
                        }

                # for learning-rate reduction
                learning_rate_reduction: {
                    patience: 5,
                    factor: 0.98,
                    min: 5.0e-4,
                    stop_at_min: True,
                    resume_lr: True,
                    }

                #  optimizer: L-BFGS-B
                #  opt_params: { "maxcor": 100, "maxls": 20 }

                ## needed for low-energy tier metrics and for "convex_hull"-based distance of energy-based weighting scheme
                compute_convex_hull: False
                batch_size: "skopt.space.Integer(32, 64)" # Important hyperparameter for Adam and irrelevant (but must be) for L-BFGS-B
                test_batch_size: 128 # test batch size (optional)

                jit_compile: True
                #  eval_init_stats: True # to evaluate initial metrics

                train_max_n_buckets: 10 # max number of buckets (group of batches of same shape) in train set
                test_max_n_buckets: 5 # same for test

                checkpoint_freq: 2 # frequency for **REGULAR** checkpoints.
                # save_all_regular_checkpoints: True # to store ALL regular checkpoints
                progressbar: False 
                # show batch-evaluation progress bar
                train_shuffle: True 
                # shuffle train batches on every epoch
            },
        }
    }
}
